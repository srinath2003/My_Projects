{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2e02c348-9592-4510-8172-546fcd9a03ac",
   "metadata": {},
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Paths to the dataset directories\n",
    "base_path = 'C:\\\\Users\\\\srina\\\\#Python_Projects\\\\Elephant_project_rework\\\\new_data'\n",
    "categories = ['buffalo', 'elephant', 'rhino', 'zebra']\n",
    "\n",
    "# Paths to train and validation directories\n",
    "train_path = os.path.join(base_path, 'train')\n",
    "val_path = os.path.join(base_path, 'val')\n",
    "\n",
    "# Create train and validation directories\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "# Create subdirectories for each category in train and val directories\n",
    "for category in categories:\n",
    "    os.makedirs(os.path.join(train_path, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_path, category), exist_ok=True)\n",
    "\n",
    "# Split ratio\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Function to split data\n",
    "def split_data(category):\n",
    "    category_path = os.path.join(base_path, category)\n",
    "    \n",
    "    if not os.path.exists(category_path):\n",
    "        print(f\"Directory not found for category {category}\")\n",
    "        return\n",
    "\n",
    "    files = os.listdir(category_path)\n",
    "    image_files = [f for f in files if f.endswith('.jpg') or f.endswith('.png')]\n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    split_index = int(len(image_files) * split_ratio)\n",
    "    train_files = image_files[:split_index]\n",
    "    val_files = image_files[split_index:]\n",
    "\n",
    "    for file in train_files:\n",
    "        shutil.move(os.path.join(category_path, file),\n",
    "                    os.path.join(train_path, category, file))\n",
    "        label_file = file.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "        shutil.move(os.path.join(category_path, label_file),\n",
    "                    os.path.join(train_path, category, label_file))\n",
    "\n",
    "    for file in val_files:\n",
    "        shutil.move(os.path.join(category_path, file),\n",
    "                    os.path.join(val_path, category, file))\n",
    "        label_file = file.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "        shutil.move(os.path.join(category_path, label_file),\n",
    "                    os.path.join(val_path, category, label_file))\n",
    "\n",
    "# Split data for each category\n",
    "for category in categories:\n",
    "    split_data(category)\n",
    "\n",
    "print(\"Dataset splitting complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b02b1e-9771-4729-bdca-9c36949a078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196  Python-3.12.4 torch-2.3.1 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Setup complete  (12 CPUs, 15.8 GB RAM, 392.9/425.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# # Pip install method (recommended)\n",
    "\n",
    "# !pip install ultralytics==8.0.196\n",
    "\n",
    "# from IPython import display\n",
    "# display.clear_output()\n",
    "\n",
    "# import ultralytics\n",
    "# ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0692fe8-bb39-4d24-b570-2aea9c861c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cae16f-5d34-44bd-a2d5-ac425c0aa10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd C:\\Users\\srina\\#Python_Projects\\Elephant_project_rework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b89d2-f54b-4dea-b92c-b94698cee8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data=new_data.yaml epochs=25 imgsz=800 plots=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f0cf6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.3.1\n",
      "CUDA Version: 11.8\n",
      "Is CUDA available? True\n",
      "GPU Device Name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.63 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=new_data.yaml, epochs=25, patience=50, batch=16, imgsz=800, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train5\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117596  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11137148 parameters, 11137132 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\srina\\#Python_Projects\\Elephant_project_rework\\new_data\\train\\buffalo.cache... 1178 images, 0 \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\srina\\#Python_Projects\\Elephant_project_rework\\new_data\\val\\buffalo.cache... 301 images, 0 backg\u001b[0m\n",
      "Plotting labels to runs\\detect\\train5\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 800 train, 800 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train5\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/25       6.1G     0.7968      1.767      1.268         36        800: 100%|██████████| 74/74 [00:26<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09\n",
      "                   all        301        548      0.708      0.735      0.776      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/25      6.13G     0.8975      1.082      1.317         40        800: 100%|██████████| 74/74 [00:28<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08\n",
      "                   all        301        548      0.702      0.634      0.674      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/25      6.14G     0.9669      1.119      1.373         42        800: 100%|██████████| 74/74 [00:27<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06\n",
      "                   all        301        548      0.689       0.59      0.659      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/25      6.14G      1.008      1.182        1.4         28        800: 100%|██████████| 74/74 [00:27<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06\n",
      "                   all        301        548       0.66      0.632      0.694      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/25       6.3G     0.9482      1.041      1.343         44        800: 100%|██████████| 74/74 [00:35<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:25\n",
      "                   all        301        548      0.595      0.509      0.552      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/25       6.3G     0.9441      1.014      1.348         34        800: 100%|██████████| 74/74 [02:01<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10\n",
      "                   all        301        548       0.74       0.64      0.762      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/25      6.17G     0.9072     0.8932      1.322         37        800: 100%|██████████| 74/74 [00:32<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07\n",
      "                   all        301        548      0.803      0.743      0.836      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/25      6.19G     0.8707     0.8774       1.29         44        800: 100%|██████████| 74/74 [00:32<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06\n",
      "                   all        301        548      0.822      0.784      0.873       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/25      6.14G     0.8458     0.8342      1.275         45        800: 100%|██████████| 74/74 [00:29<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06\n",
      "                   all        301        548      0.874      0.826      0.903      0.673\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/25      6.13G     0.8339     0.7972      1.259         28        800: 100%|██████████| 74/74 [00:33<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:16\n",
      "                   all        301        548      0.862      0.808      0.887      0.673\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/25      6.18G     0.8015     0.7391      1.228         42        800: 100%|██████████| 74/74 [00:31<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06\n",
      "                   all        301        548      0.847      0.776      0.874      0.661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/25      6.17G      0.772     0.7309      1.218         49        800: 100%|██████████| 74/74 [00:29<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07\n",
      "                   all        301        548      0.844      0.833      0.915      0.696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/25      6.17G     0.7607     0.7122      1.218         31        800: 100%|██████████| 74/74 [00:29<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07\n",
      "                   all        301        548      0.867      0.832      0.907      0.697\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/25      6.18G     0.7462     0.6909      1.194         42        800: 100%|██████████| 74/74 [00:32<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:19\n",
      "                   all        301        548      0.875      0.842      0.914      0.701\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/25      6.19G     0.7222     0.6718      1.183         44        800: 100%|██████████| 74/74 [01:21<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09\n",
      "                   all        301        548      0.882      0.864       0.93      0.722\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/25      6.15G     0.6833     0.6273      1.194         26        800: 100%|██████████| 74/74 [00:29<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07\n",
      "                   all        301        548      0.855      0.851      0.906      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/25      6.14G      0.674     0.5706      1.179         19        800: 100%|██████████| 74/74 [00:29<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06\n",
      "                   all        301        548      0.873      0.829       0.91      0.722\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/25      6.13G     0.6551     0.5309       1.16         23        800: 100%|██████████| 74/74 [00:29<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:17\n",
      "                   all        301        548       0.92      0.804      0.909       0.72\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/25      6.16G     0.6246     0.4952      1.137         21        800: 100%|██████████| 74/74 [00:46<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:11\n",
      "                   all        301        548      0.926      0.855      0.939      0.741\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/25      6.13G     0.5939     0.4674      1.114         14        800: 100%|██████████| 74/74 [00:27<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07\n",
      "                   all        301        548      0.925      0.861      0.941      0.755\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/25      6.14G     0.5782     0.4472      1.086         17        800: 100%|██████████| 74/74 [00:30<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06\n",
      "                   all        301        548      0.914      0.867      0.942      0.764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/25      6.13G     0.5572     0.4214      1.077         12        800: 100%|██████████| 74/74 [00:30<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10\n",
      "                   all        301        548      0.873       0.91      0.949      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/25      6.13G     0.5343     0.3945      1.048         17        800: 100%|██████████| 74/74 [00:54<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:11\n",
      "                   all        301        548      0.893      0.891      0.954       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/25      6.14G     0.5106     0.3803      1.031         15        800: 100%|██████████| 74/74 [00:27<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06\n",
      "                   all        301        548      0.931      0.899      0.959      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/25      6.14G     0.5064     0.3632      1.022         22        800: 100%|██████████| 74/74 [00:29<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06\n",
      "                   all        301        548      0.931      0.897      0.956      0.787\n",
      "\n",
      "25 epochs completed in 0.346 hours.\n",
      "Optimizer stripped from runs\\detect\\train5\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from runs\\detect\\train5\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating runs\\detect\\train5\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.196  Python-3.12.4 torch-2.3.1 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 168 layers, 11127132 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03\n",
      "                   all        301        548      0.929        0.9      0.959      0.788\n",
      "               buffalo        301        101      0.949      0.923      0.967      0.828\n",
      "              elephant        301        172      0.909      0.831      0.933      0.725\n",
      "                 rhino        301        117      0.929      0.923      0.981      0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 zebra        301        158      0.928      0.924      0.955      0.754\n",
      "Speed: 0.4ms preprocess, 4.4ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1, 2, 3])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C2FE4C6D50>\n",
       "fitness: 0.80466547677519\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.82804,     0.72539,     0.84231,     0.75429])\n",
       "names: {0: 'buffalo', 1: 'elephant', 2: 'rhino', 3: 'zebra'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9287462412061198, 'metrics/recall(B)': 0.9004895260261093, 'metrics/mAP50(B)': 0.959077321959212, 'metrics/mAP50-95(B)': 0.7875086050880764, 'fitness': 0.80466547677519}\n",
       "save_dir: WindowsPath('runs/detect/train5')\n",
       "speed: {'preprocess': 0.4351756897479593, 'inference': 4.430733645873213, 'loss': 0.0, 'postprocess': 1.176586182806579}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Check PyTorch and CUDA setup\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"Is CUDA available?\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Device Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Set working directory\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\srina\\#Python_Projects\\Elephant_project_rework')\n",
    "\n",
    "# Ensure YOLO uses GPU\n",
    "model = YOLO('yolov8s.pt')  # Load the model\n",
    "model.to('cuda')  # Move the model to GPU\n",
    "\n",
    "# Train the model\n",
    "model.train(data='new_data.yaml', epochs=25, imgsz=800, plots=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a2ae0e-7acc-43d2-9486-e059e0418aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.60 ðŸš€ Python-3.8.0 torch-2.2.1+cpu CPU (11th Gen Intel Core(TM) i5-11400H 2.70GHz)\n",
      "Model summary (fused): 168 layers, 11,127,132 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                   all        301        548      0.906      0.801      0.901      0.707\n",
      "               buffalo         75        101      0.898      0.851      0.953      0.789\n",
      "              elephant         77        172      0.887      0.638      0.815      0.625\n",
      "                 rhino         75        117      0.899      0.855      0.905      0.739\n",
      "                 zebra         76        158       0.94      0.861       0.93      0.677\n",
      "Speed: 3.8ms preprocess, 627.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val3\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\srina\\#Python_Projects\\Elephant_project_rework\\new_data\\val\\buffalo.cache... 301 images, 0 backgrounds, 0 corrupt: 100%|##########| 301/301 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\srina\\#Python_Projects\\Elephant_project_rework\\new_data\\val\\buffalo.cache... 301 images, 0 backgrounds, 0 corrupt: 100%|##########| 301/301 [00:00<?, ?it/s]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/19 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   5%|5         | 1/19 [00:08<02:40,  8.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  11%|#         | 2/19 [00:17<02:28,  8.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  16%|#5        | 3/19 [00:26<02:22,  8.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  21%|##1       | 4/19 [00:36<02:17,  9.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  26%|##6       | 5/19 [00:46<02:13,  9.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  32%|###1      | 6/19 [00:55<02:03,  9.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  37%|###6      | 7/19 [01:05<01:54,  9.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  42%|####2     | 8/19 [01:15<01:45,  9.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  47%|####7     | 9/19 [01:24<01:35,  9.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  53%|#####2    | 10/19 [01:34<01:26,  9.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  58%|#####7    | 11/19 [01:43<01:16,  9.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  63%|######3   | 12/19 [01:54<01:09,  9.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  68%|######8   | 13/19 [02:05<01:00, 10.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  74%|#######3  | 14/19 [02:16<00:52, 10.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  79%|#######8  | 15/19 [02:27<00:42, 10.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  84%|########4 | 16/19 [02:38<00:32, 10.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  89%|########9 | 17/19 [02:51<00:23, 11.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  95%|#########4| 18/19 [03:06<00:12, 12.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 19/19 [03:14<00:00, 11.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 19/19 [03:14<00:00, 10.25s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=val model=runs/detect/train/weights/best.pt data=new_data.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af39f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f4653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a6c6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b986f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c8381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f5fae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df86e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c7c890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ed125cb-ef7b-478c-a308-d603df6cfc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196  Python-3.12.4 torch-2.3.1 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 168 layers, 11127132 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\srina\\#Python_Projects\\Elephant_project_rework\\Custom_testing_image\\7061.png: 480x800 2 elephants, 95.4ms\n",
      "Speed: 0.0ms preprocess, 95.4ms inference, 57.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo detect predict model=runs/detect/train/weights/best.pt source=\"C:\\Users\\srina\\#Python_Projects\\Elephant_project_rework\\Custom_testing_image\\7061.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db205d30-2265-4bbf-ad60-694f98708fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo detect predict model=runs/detect/train/weights/best.pt source=\"C:\\Users\\srina\\#Python_Projects\\Elephant_project_rework\\Custom_testing_image\" project=\"C:\\Users\\srina\\#Python_Projects\\Elephant_project_rework\\Custom_testing_results\" name=\"batch_results\" save=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270f99f-23c0-4b46-afad-41d6c2fb6e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_gpu)",
   "language": "python",
   "name": "torch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
