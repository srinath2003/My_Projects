{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Sample text data\n",
        "text_data = \"This is RNN model , LSTM architecture .This model predict next word \"\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text_data])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "\n",
        "# Create input sequences and labels\n",
        "input_sequences = []\n",
        "for line in text_data.split('.'):\n",
        "\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "max_sequence_length = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential([\n",
        "    Embedding(total_words, 50, input_length=max_sequence_length-1),\n",
        "    LSTM(100),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "\n",
        "def generate_text(seed_text, next_words, model, max_sequence_length, tokenizer):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_index = np.argmax(predicted_probs)\n",
        "\n",
        "        # Convert the predicted index to the corresponding word\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Generate text predictions\n",
        "generated_text = generate_text(\"this is \", 4, model, max_sequence_length, tokenizer)\n",
        "print(\"\\nGenerated Text:\")\n",
        "print(generated_text)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP5XlHO74u_7",
        "outputId": "16bf23da-ac1a-484d-f5c6-41f8c7e55af8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.3066 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3006 - accuracy: 0.1111\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2947 - accuracy: 0.4444\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2888 - accuracy: 0.2222\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2828 - accuracy: 0.2222\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2766 - accuracy: 0.2222\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2702 - accuracy: 0.2222\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2636 - accuracy: 0.2222\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2565 - accuracy: 0.2222\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2490 - accuracy: 0.2222\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2410 - accuracy: 0.2222\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2324 - accuracy: 0.2222\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2230 - accuracy: 0.2222\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.2128 - accuracy: 0.2222\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2017 - accuracy: 0.2222\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1896 - accuracy: 0.2222\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1763 - accuracy: 0.2222\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.1618 - accuracy: 0.2222\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1459 - accuracy: 0.2222\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1284 - accuracy: 0.2222\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1094 - accuracy: 0.2222\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0888 - accuracy: 0.2222\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0666 - accuracy: 0.2222\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0429 - accuracy: 0.2222\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0182 - accuracy: 0.2222\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9931 - accuracy: 0.2222\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.9685 - accuracy: 0.2222\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9455 - accuracy: 0.2222\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9251 - accuracy: 0.2222\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9069 - accuracy: 0.2222\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8886 - accuracy: 0.2222\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.8674 - accuracy: 0.2222\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8419 - accuracy: 0.2222\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8123 - accuracy: 0.2222\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.7800 - accuracy: 0.2222\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7467 - accuracy: 0.3333\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7135 - accuracy: 0.3333\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6805 - accuracy: 0.3333\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6474 - accuracy: 0.3333\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6132 - accuracy: 0.3333\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.5770 - accuracy: 0.5556\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.5381 - accuracy: 0.5556\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4962 - accuracy: 0.5556\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4516 - accuracy: 0.5556\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4053 - accuracy: 0.5556\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3584 - accuracy: 0.5556\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3120 - accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.2661 - accuracy: 0.6667\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2202 - accuracy: 0.6667\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1736 - accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1264 - accuracy: 0.6667\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0798 - accuracy: 0.6667\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0353 - accuracy: 0.6667\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.9933 - accuracy: 0.6667\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9524 - accuracy: 0.7778\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9113 - accuracy: 0.7778\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8705 - accuracy: 0.7778\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8313 - accuracy: 0.7778\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7945 - accuracy: 0.7778\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7596 - accuracy: 0.7778\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7262 - accuracy: 0.7778\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6950 - accuracy: 0.7778\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6665 - accuracy: 0.7778\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6399 - accuracy: 0.7778\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6151 - accuracy: 0.7778\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5929 - accuracy: 0.7778\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5723 - accuracy: 0.8889\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5526 - accuracy: 0.8889\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5346 - accuracy: 0.7778\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5182 - accuracy: 0.7778\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5025 - accuracy: 0.8889\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4880 - accuracy: 0.8889\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4749 - accuracy: 0.8889\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4621 - accuracy: 0.8889\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4496 - accuracy: 0.8889\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4374 - accuracy: 0.8889\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4252 - accuracy: 0.8889\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4137 - accuracy: 0.8889\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4026 - accuracy: 0.8889\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3922 - accuracy: 0.8889\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3828 - accuracy: 0.8889\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3739 - accuracy: 0.8889\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3654 - accuracy: 0.8889\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3570 - accuracy: 0.8889\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3487 - accuracy: 0.8889\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3408 - accuracy: 0.8889\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3332 - accuracy: 0.8889\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3260 - accuracy: 0.8889\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3191 - accuracy: 0.8889\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3123 - accuracy: 0.8889\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3058 - accuracy: 0.8889\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2993 - accuracy: 0.8889\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2931 - accuracy: 0.8889\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2870 - accuracy: 0.8889\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2812 - accuracy: 0.8889\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2757 - accuracy: 0.8889\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2705 - accuracy: 0.8889\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2655 - accuracy: 0.8889\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2607 - accuracy: 0.8889\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2561 - accuracy: 0.8889\n",
            "\n",
            "Generated Text:\n",
            "this is  rnn model lstm architecture\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jlJT952Z78lz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}